import shutil
import os
import zipfile
import uuid
import io
import uvicorn
from pathlib import Path

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import StreamingResponse, JSONResponse, RedirectResponse
from fastapi.middleware.cors import CORSMiddleware  # Import the CORS middleware
from fastapi.openapi.utils import get_openapi

# Assuming these are in separate files as in the original code
# You would need to create these files: gemini_utils.py, project_documenter.py, pipeline_utils.py
# For demonstration, we'll create dummy functions if they don't exist.

# --- Dummy Implementations (Replace with your actual files) ---
try:
    from gemini_utils import configure_gemini
except ImportError:
    print("Warning: 'gemini_utils' not found. Using dummy function.")
    def configure_gemini():
        # This is a placeholder for your actual Gemini model configuration
        class DummyModel:
            def generate_content(self, text):
                return f"Generated documentation for: {text}"
        return DummyModel()

try:
    from project_documenter import generate_project_documentation
except ImportError:
    print("Warning: 'project_documenter' not found. Using dummy function.")
    def generate_project_documentation(path, model, output_file):
        with open(output_file, "w") as f:
            f.write("# Auto-Generated Project Documentation\n\n")
            f.write("This README.md was generated by the AI Project Documenter.\n")
            f.write(f"Source Path: {path}\n")

try:
    from pipeline_utils import process_file_docstring_and_comment
except ImportError:
    print("Warning: 'pipeline_utils' not found. Using dummy function.")
    def process_file_docstring_and_comment(in_path, out_path, model):
        # This function would read a python file, add docstrings/comments, and write to a new file.
        # For this dummy version, we'll just copy the file.
        out_path.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy(in_path, out_path)
# --- End of Dummy Implementations ---


# --- FastAPI Application Setup ---
# Add metadata for the Swagger UI documentation
app = FastAPI(
    title="Unified AI Project Processor",
    description="""
    This API processes a zipped Python project. It performs the following tasks:
    1.  Adds docstrings and comments to each `.py` file using a generative AI model.
    2.  Generates a `README.md` file for the entire project.
    3.  Returns a new zip file containing the processed files and the README.
    """,
    version="1.0.0",
)

# --- CORS (Cross-Origin Resource Sharing) Middleware ---
# Define the specific origins that are allowed to make requests.
# This is a more secure and reliable approach for deployment than a wildcard (*).
origins = [
    "https://document-generator-cz1m.onrender.com", # Your production frontend
    "http://localhost",
    "http://localhost:8000",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],  # Allows all methods (GET, POST, etc.)
    allow_headers=["*"],  # Allows all headers
)


# --- Directory Setup ---
BASE_DIR = Path(__file__).resolve().parent
TEMP_DIR = BASE_DIR / "temp"
TEMP_DIR.mkdir(exist_ok=True)

# --- Model Configuration ---
# This should be your actual model initialization
model = configure_gemini()

# --- Utility Functions ---

def extract_zip(zip_path: Path, extract_to: Path):
    """Extracts a zip file to a specified directory."""
    try:
        with zipfile.ZipFile(zip_path, "r") as zip_ref:
            zip_ref.extractall(extract_to)
    except zipfile.BadZipFile:
        raise HTTPException(status_code=400, detail="Invalid ZIP file provided.")

def zip_folder_to_bytesio(source_dir: Path) -> io.BytesIO:
    """Zips an entire folder and returns it as an in-memory BytesIO object."""
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zipf:
        for file_path in source_dir.rglob("*"):
            if file_path.is_file():
                # Create a relative path for files in the zip archive
                arcname = file_path.relative_to(source_dir)
                zipf.write(file_path, arcname)
    zip_buffer.seek(0)
    return zip_buffer

# --- API Endpoints ---

@app.get("/", include_in_schema=False)
async def root():
    """
    Redirects the root URL to the API documentation.
    """
    return RedirectResponse(url="/docs")

@app.get("/health", tags=["Health Check"], include_in_schema=False)
async def health_check():
    """
    A simple endpoint that hosting platforms can use to verify the service is running.
    """
    return {"status": "ok"}


@app.post(
    "/process-project/",
    tags=["Project Processing"],
    summary="Process a Zipped Python Project",
    description="Upload a .zip file containing a Python project to add AI-generated documentation and comments.",
    responses={
        200: {
            "description": "Success. Returns a processed .zip file.",
            "content": {
                "application/zip": {
                    "schema": {
                        "type": "string",
                        "format": "binary"
                    }
                }
            }
        },
        500: {
            "description": "Internal Server Error. An issue occurred during processing.",
            "content": {
                "application/json": {
                    "schema": {
                        "type": "object",
                        "properties": {
                            "error": {"type": "string"}
                        }
                    }
                }
            }
        },
    }
)
async def process_project(
    file: UploadFile = File(..., description="A .zip file containing the Python project source code.")
):
    """
    Main endpoint to handle the project processing pipeline.
    """
    # Generate a unique ID for this request to handle directories safely
    uid = str(uuid.uuid4())
    request_temp_dir = TEMP_DIR / uid
    zip_path = request_temp_dir / f"{file.filename}"
    src_dir = request_temp_dir / "src"
    processed_dir = request_temp_dir / "processed"
    output_dir = request_temp_dir / "output" # This will be the final zipped folder

    # Create all necessary directories
    for d in [src_dir, processed_dir, output_dir]:
        d.mkdir(parents=True, exist_ok=True)

    try:
        # 1. Save the uploaded ZIP file
        with open(zip_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)

        # 2. Extract the source code from the ZIP
        extract_zip(zip_path, src_dir)

        # 3. Process each .py file (add docstrings and comments)
        py_files = list(src_dir.rglob("*.py"))
        for py_file in py_files:
            rel_path = py_file.relative_to(src_dir)
            out_file_path = processed_dir / rel_path
            # Ensure the parent directory of the output file exists
            out_file_path.parent.mkdir(parents=True, exist_ok=True)
            process_file_docstring_and_comment(py_file, out_file_path, model)

        # 4. Copy non-python files from source to processed directory
        for item in src_dir.iterdir():
            source_item = src_dir / item.name
            dest_item = processed_dir / item.name
            if source_item.is_dir():
                 # Exclude __pycache__ and other dot-folders
                if not item.name.startswith('.') and item.name != '__pycache__':
                    shutil.copytree(source_item, dest_item, dirs_exist_ok=True)
            elif not item.name.endswith('.py'):
                shutil.copy2(source_item, dest_item)


        # 5. Generate a new README.md for the project
        readme_path = output_dir / "README.md"
        generate_project_documentation(str(src_dir), model, output_file=readme_path)

        # 6. Copy processed files into the final output directory
        shutil.copytree(processed_dir, output_dir / "processed_project", dirs_exist_ok=True)

        # 7. Zip the final output directory and return it as a stream
        zip_stream = zip_folder_to_bytesio(output_dir)
        return StreamingResponse(
            zip_stream,
            media_type="application/zip",
            headers={"Content-Disposition": "attachment; filename=processed_project.zip"}
        )

    except Exception as e:
        # In case of any error, return a JSON response
        return JSONResponse(status_code=500, content={"error": str(e)})

    finally:
        # 8. Clean up temporary directories and files
        shutil.rmtree(request_temp_dir, ignore_errors=True)


# To run this application:
# 1. Save the code as a Python file (e.g., `main.py`).
# 2. Make sure you have the necessary libraries: pip install fastapi "uvicorn[standard]"
# 3. Run the server from your terminal: uvicorn main:app --reload
# 4. Open your browser and go to http://127.0.0.1:8000 to be redirected to the docs.

if __name__ == "__main__":
    # For deployment, get the port from the environment variable or default to 8000
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
